
import os
import json
import time
import numpy as np
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
import warnings
from tqdm import tqdm

warnings.filterwarnings("ignore")

# ===========================
# Configuration
# ===========================
DATA_PATH = os.path.join(os.path.dirname(__file__), "data", "poc_v2_mock_product_db.json")
TEST_CASES_PATH = os.path.join(os.path.dirname(__file__), "data", "poc_v2_golden_test_cases.json")
LOCAL_MODEL_NAME = "paraphrase-multilingual-MiniLM-L12-v2"

class SearchEngine:
    def __init__(self):
        print("ğŸ”§ Initializing Search Engine...")
        self.products = []
        self.bm25 = None
        self.vector_model = None
        self.product_embeddings = None
        self.corpus_tokenized = []
        
        self._load_data()
        self._build_indices()
        
    def _load_data(self):
        if not os.path.exists(DATA_PATH):
            raise FileNotFoundError(f"Mock DB not found at {DATA_PATH}")
        with open(DATA_PATH, "r", encoding="utf-8") as f:
            self.products = json.load(f)
        print(f"ğŸ“¦ Loaded {len(self.products)} products.")

    def _build_indices(self):
        # 1. BM25 Index
        print("ğŸ“ Building BM25 Index...")
        # Tokenize simply by whitespace for this PoC (Korean specific tokenization would be better but keeping simple)
        self.corpus_tokenized = [self.tokenize(f"{p['name']} {p.get('searchable_desc','')} {p['category_middle']}") for p in self.products]
        self.bm25 = BM25Okapi(self.corpus_tokenized)
        
        # 2. Vector Index
        print(f"ğŸ§  Loading Vector Model ({LOCAL_MODEL_NAME})...")
        self.vector_model = SentenceTransformer(LOCAL_MODEL_NAME)
        print("ğŸ§® Encoding Product Vectors...")
        texts = [f"{p['name']} {p['category_middle']} {p.get('desc','')} {p.get('searchable_desc','')}" for p in self.products]
        self.product_embeddings = self.vector_model.encode(texts, show_progress_bar=True)
        
    def tokenize(self, text):
        return text.lower().split()

    # ===========================
    # Search Methods
    # ===========================
    
    def search_term_match(self, query, top_k=20):
        # Simple scorer: count overlapping tokens
        q_tokens = set(self.tokenize(query))
        scores = []
        for p in self.products:
            p_text = (p['name'] + " " + p.get('searchable_desc', '')).lower()
            score = sum(1 for t in q_tokens if t in p_text)
            scores.append(score)
        
        # Sort
        top_indices = np.argsort(scores)[::-1][:top_k]
        return [self.products[i] for i in top_indices if scores[i] > 0]

    def search_bm25(self, query, top_k=20):
        tokenized_query = self.tokenize(query)
        scores = self.bm25.get_scores(tokenized_query)
        top_indices = np.argsort(scores)[::-1][:top_k]
        return [self.products[i] for i in top_indices]

    def search_vector(self, query, top_k=20):
        q_vec = self.vector_model.encode([query])[0]
        scores = np.dot(self.product_embeddings, q_vec) # Assuming normalized if cosine, but Dot is fine for ranking
        # Normalization check
        # norm_doc = np.linalg.norm(self.product_embeddings, axis=1)
        # norm_query = np.linalg.norm(q_vec)
        # scores = scores / (norm_doc * norm_query)
        
        top_indices = np.argsort(scores)[::-1][:top_k]
        return [self.products[i] for i in top_indices]
    
    def search_hybrid(self, query, top_k=20, alpha=0.5):
        # RRF or Weighted Sum? Let's use Weighted Sum of normalized scores for simplicity
        
        # BM25 Scores
        tokenized_query = self.tokenize(query)
        bm25_scores = self.bm25.get_scores(tokenized_query)
        if bm25_scores.max() > 0:
            bm25_scores = bm25_scores / bm25_scores.max() # Normalize 0-1
            
        # Vector Scores
        q_vec = self.vector_model.encode([query])[0]
        vec_scores = np.dot(self.product_embeddings, q_vec)
        if vec_scores.max() > 0:
            vec_scores = vec_scores / vec_scores.max() # Normalize 0-1
        
        final_scores = (xml_score := alpha * vec_scores + (1-alpha) * bm25_scores)
        
        top_indices = np.argsort(final_scores)[::-1][:top_k]
        return [self.products[i] for i in top_indices]

# ===========================
# Experiment Runner
# ===========================
def run_experiment():
    if not os.path.exists(TEST_CASES_PATH):
        print("âŒ Test cases not found.")
        return
        
    engine = SearchEngine()
    
    with open(TEST_CASES_PATH, "r", encoding="utf-8") as f:
        cases = json.load(f)
        
    print("\nğŸ§ª Starting Top-K Sensitivity Test (K=[5, 10, 20])...")
    
    k_list = [5, 10, 20]
    methods = ["BM25", "Vector", "Hybrid"]
    
    results = {m: {k: {"recall": 0} for k in k_list} for m in methods}
    total_cases = len(cases)
    
    for case in tqdm(cases):
        query = case['query']
        ground_truth = set(case.get('ground_truth_ids_hint', []))
        if not ground_truth: continue # Skip if no truth defined
        
        # Run Searches
        res_bm25 = engine.search_bm25(query, top_k=20)
        res_vec = engine.search_vector(query, top_k=20)
        res_hybrid = engine.search_hybrid(query, top_k=20)
        
        res_dict = {"BM25": res_bm25, "Vector": res_vec, "Hybrid": res_hybrid}
        
        for method, items in res_dict.items():
            retrieved_ids = [p['id'] for p in items]
            
            for k in k_list:
                # Check if ANY ground truth is in Top-K (Hit Rate / Recall@K logic)
                # Actually, strictly Recall is (Relevant Items Retrieved / Total Relevant).
                # Here we check "Intersection Count"
                top_k_ids = set(retrieved_ids[:k])
                intersection = top_k_ids.intersection(ground_truth)
                if intersection:
                    results[method][k]["recall"] += 1 # Increment "Hit" count for now
    
    print("\nğŸ“Š Results (Hit Rate @ K)")
    print(f"{'Method':<10} | {'@5':<10} | {'@10':<10} | {'@20':<10}")
    print("-" * 50)
    for m in methods:
        row = f"{m:<10}"
        for k in k_list:
            hit_count = results[m][k]["recall"]
            rate = (hit_count / total_cases) * 100
            row += f" | {rate:.1f}% ({hit_count})"
        print(row)

if __name__ == "__main__":
    run_experiment()



"""
ê²€ìƒ‰ ì—”ì§„ì˜ í•µì‹¬(Retrieval) ì„±ëŠ¥ì„ ê²€ì¦í•˜ëŠ” ì‹¤í—˜ì‹¤ì…ë‹ˆë‹¤.

Step 1ì—ì„œ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³  ë‚˜ë©´, ì‹¤ì œë¡œ ìˆ˜ë§ì€ ìƒí’ˆ ì¤‘ì—ì„œ **"ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì°¾ì•„ì•¼ ì •ë‹µì´ ë‚˜ì˜¬ê¹Œ?"**ë¥¼ ê²½ìŸì‹œí‚¤ëŠ” ì½”ë“œì…ë‹ˆë‹¤.

í•µì‹¬ ê¸°ëŠ¥ ì„¤ëª…
SearchEngine
 í´ë˜ìŠ¤ (ê²€ìƒ‰ ì—”ì§„ ë³¸ì²´):
ì¸ë±ì‹± (ì¤€ë¹„ ë‹¨ê³„):
BM25: ìƒí’ˆëª…ê³¼ ì„¤ëª…ì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ í†µê³„ì  ì ìˆ˜(í¬ì†Œì„±)ë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•´ë‘¡ë‹ˆë‹¤.
Vector: SentenceTransformer ëª¨ë¸ì„ ì¨ì„œ ëª¨ë“  ìƒí’ˆì„ 384ì°¨ì›ì˜ ìˆ«ì(ë²¡í„°)ë¡œ ë³€í™˜í•´ë‘¡ë‹ˆë‹¤.
ê²€ìƒ‰ ë©”ì„œë“œ 3ì¢… ì„¸íŠ¸:
search_term_match
: ë‹¨ìˆœíˆ ë‹¨ì–´ê°€ í¬í•¨ëëŠ”ì§€ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤. (ê°€ì¥ ê¸°ì´ˆì )
search_bm25
: í‚¤ì›Œë“œì˜ ì¤‘ìš”ë„(ë¹ˆë„)ë¥¼ ë”°ì ¸ì„œ ì°¾ìŠµë‹ˆë‹¤. (ë‹¨ì–´ ë§¤ì¹­ì˜ ì§„í™”í˜•)
search_vector
: ë‹¨ì–´ê°€ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë¹„ìŠ·í•˜ë©´ ì°¾ìŠµë‹ˆë‹¤. (ì˜ˆ: "ë¬¼ê¸° ì œê±°" <-> "ê±´ì¡°")
search_hybrid
 (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰):
BM25 ì ìˆ˜ + ë²¡í„° ì ìˆ˜ë¥¼ ë°˜ë°˜(0.5:0.5 ë˜ëŠ” ì¡°ì ˆ ê°€ëŠ¥) ì„ì–´ì„œ ìµœì¢… ìˆœìœ„ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
ë‹¨ì–´ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²ƒë„ ì°¾ê³ , ì˜ë¯¸ê°€ í†µí•˜ëŠ” ê²ƒë„ ì°¾ê¸° ìœ„í•œ **"í•„ìŠ¹ ì „ëµ"**ì…ë‹ˆë‹¤.
run_experiment
 (Top-K ì‹¤í—˜ê¸°):
ëª©ì : "ëª‡ ê°œë¥¼ ê°€ì ¸ì™€ì•¼ ì•ˆì „í• ê¹Œ?"ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
Step 0ì—ì„œ ë§Œë“  ì •ë‹µì§€(golden_test_cases)ë¥¼ ì‚¬ìš©í•˜ì—¬, BM25, Vector, Hybrid ë°©ì‹ ê°ê°ì— ëŒ€í•´ ì§ˆë¬¸ì„ ë˜ì§‘ë‹ˆë‹¤.
Top-5, 10, 20ê°œì”© ëŠì–´ì„œ ê°€ì ¸ì™”ì„ ë•Œ, ê·¸ ì•ˆì— ì§„ì§œ ì •ë‹µì´ ë“¤ì–´ìˆëŠ”ì§€(Hit Rate/Recall)ë¥¼ í‘œë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
ì´ ì½”ë“œê°€ ì¤‘ìš”í•œ ì´ìœ 
**"ì™œ Hybridë¥¼ ì¨ì•¼ í•˜ë‚˜ìš”?"**ë¼ëŠ” ì§ˆë¬¸ì— ë°ì´í„°ë¡œ ë‹µí•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.
"Reranking ëª¨ë¸í•œí…Œ ëª‡ ê°œë¥¼ ë„˜ê²¨ì¤˜ì•¼ í•˜ì£ ?" (5ê°œ? 20ê°œ?)ë¼ëŠ” ì§ˆë¬¸ì— ëŒ€í•´, "20ê°œë¥¼ ë„˜ê²¨ì£¼ë©´ ì •ë‹µ í¬í•¨ë¥ ì´ 95%ì§€ë§Œ ì†ë„ê°€ ëŠë¦¬ê³ , 10ê°œë©´ 90%ì…ë‹ˆë‹¤"ë¼ê³  íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ê²°ì •í•  ìˆ˜ ìˆëŠ” ê·¼ê±°ë¥¼ ì¤ë‹ˆë‹¤.
ê²°êµ­, ëˆ(LLM ë¹„ìš©/ì‹œê°„)ì„ ì“°ê¸° ì „ì— ê°€ì¥ íš¨ìœ¨ì ìœ¼ë¡œ í›„ë³´ë¥¼ ì¶”ë ¤ë‚´ëŠ” ìµœì ì˜ ì„¤ì •ì„ ì°¾ëŠ” ì½”ë“œì…ë‹ˆë‹¤.
"""